{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import pytorch_lightning as pl \n",
    "from pytorch_lightning import Trainer, LightningModule\n",
    "\n",
    "import torchdyn \n",
    "from torchdyn.core import NeuralODE\n",
    "\n",
    "import os\n",
    "import cv2 \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircuitFused(Dataset):\n",
    "    def __init__(self, datadir, image_size):\n",
    "        super().__init__()\n",
    "        self.datadir = datadir\n",
    "        self.image_size = image_size\n",
    "        self.images, self.labels = self.datareader()\n",
    "\n",
    "    def datareader(self):\n",
    "        X = []\n",
    "        Y = []\n",
    "        folders = os.listdir(self.datadir)\n",
    "        for c, folder in enumerate(folders):\n",
    "            try:\n",
    "                files = os.listdir(self.datadir+folder)\n",
    "                for file in files:\n",
    "                    image = cv2.imread(self.datadir+folder+\"/\"+file)\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                    image = cv2.resize(image, (self.image_size[0], self.image_size[1]), cv2.INTER_AREA)/255.0\n",
    "                    image = np.array(image, dtype= np.float32)\n",
    "                    arr = np.zeros(15, dtype=\"float32\")\n",
    "                    arr[int(c)]=1\n",
    "                    image = image.reshape(1, self.image_size[0], self.image_size[1])\n",
    "                    X.append(image)\n",
    "                    Y.append(arr)\n",
    "            except:\n",
    "                pass\n",
    "        return X, Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = th.from_numpy(np.array(self.labels[idx]))\n",
    "        image = th.from_numpy(np.array(self.images[idx]))\n",
    "        sample = {\"Image\": image, \"Label\": label}\n",
    "        return sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNODEBlock(nn.Module):\n",
    "    def __init__(self, filters:int, kernel:int, moment:float, alpha=0.1):\n",
    "        super(CNNODEBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(filters, filters, kernel)\n",
    "        self.act = nn.LeakyReLU(alpha)\n",
    "        self.pad = nn.ZeroPad2d(int((kernel-1)/2))\n",
    "        self.norm = nn.BatchNorm2d(filters, momentum=moment)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.norm(self.pad(self.conv(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UPBlock(nn.Module):\n",
    "    def __init__(self, infilter:int, outfilter:int, kernel:int, moment:float):\n",
    "        super(UPBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(infilter, outfilter, kernel)\n",
    "        self.norm1 = nn.BatchNorm2d(outfilter, momentum=moment)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(outfilter, outfilter, kernel)\n",
    "        self.norm2 = nn.BatchNorm2d(outfilter, momentum=moment)\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "        self.pad = nn.ZeroPad2d(int((kernel-1)/2.0))\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.act(self.norm1(self.pad(self.conv1(x))))\n",
    "        x = self.act(self.norm2(self.pad(self.conv2(x))))\n",
    "        return self.pool(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, filter:int, dense:int, drop:float, classes:int):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.flat = nn.Flatten()\n",
    "        self.dense = nn.Linear(filter, dense)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.final = nn.Linear(dense, classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.dense(self.drop(self.flat(self.pool(x))))\n",
    "        return F.softmax(self.final(self.drop(F.relu(x))), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNODE(nn.Module):\n",
    "    def __init__(self, num=3, filter=64, dense=256, classes=15, gf=2, kernel=3, moment=0.9, drop=0.2, aplha=0.1):\n",
    "        super(CNNODE, self).__init__()\n",
    "        self.cnnode = nn.ModuleList([])\n",
    "        self.upsamp = nn.ModuleList([])\n",
    "        self.final = DenseBlock(filter*pow(gf, num), dense, drop, classes)\n",
    "        self.conv = UPBlock(1, filter, kernel, moment)\n",
    "        \n",
    "        for _ in range(num):\n",
    "            f = CNNODEBlock(filter, kernel, moment, aplha)\n",
    "            model = NeuralODE(f, sensitivity='adjoint', solver='rk4', solver_adjoint='dopri5', atol_adjoint=1e-4, rtol_adjoint=1e-4)\n",
    "            self.cnnode.append(model)\n",
    "            self.upsamp.append(UPBlock(filter, filter*2, kernel, moment))\n",
    "            filter = filter*gf\n",
    "\n",
    "    def forward(self, x, t_span):\n",
    "        x = self.conv(x)\n",
    "        for neuralode, neuralnetwork in zip(self.cnnode, self.upsamp):\n",
    "            # t, x = neuralode(x, t_span)\n",
    "            x = neuralnetwork(x)\n",
    "        return self.final(x)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner(LightningModule):\n",
    "    def __init__(self, data:Dataset, model:nn.Module, t_span:th.tensor,  batchsize:int=20, learning_rate:float=1e-4, split=0.8):\n",
    "        super(Learner, self).__init__()\n",
    "        self.split = int(split*data.__len__())\n",
    "        self.model, self.t_span = model, t_span\n",
    "        self.data, self.valid = random_split(data, [self.split, data.__len__()-self.split])\n",
    "        self.batchsize = batchsize\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch[\"Image\"]\n",
    "        y = batch[\"Label\"]\n",
    "        y_hat = self.model(x, self.t_span)\n",
    "        loss = nn.CrossEntropyLoss()(y_hat, y)\n",
    "        accuracy = self.acc(y_hat, y)\n",
    "        cur_lr = self.trainer.optimizers[0].param_groups[0]['lr']\n",
    "        self.log(\"lr\", cur_lr, prog_bar=True, on_step=True)\n",
    "        self.log_dict({\"my_lr\": cur_lr, \"traning_loss\": loss, \"Accuracy\": accuracy}, on_step=True, on_epoch=True, prog_bar=True, logger=False)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x = batch[\"Image\"]\n",
    "        y = batch[\"Label\"]\n",
    "        y_hat = self.model(x, self.t_span)\n",
    "        loss = nn.CrossEntropyLoss()(y_hat, y)\n",
    "        accuracy = self.acc(y_hat, y)\n",
    "        self.log_dict({\"valid_loss\": loss, \"valid_Acc\": accuracy}, on_step=True, on_epoch=True, prog_bar=True, logger=False)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr =self.learning_rate)\n",
    "        sch = optim.lr_scheduler.StepLR(\n",
    "        optimizer, step_size  = 10 , gamma = 0.1)\n",
    "        return {\n",
    "            \"optimizer\":optimizer,\n",
    "            \"lr_scheduler\" : {\n",
    "                \"scheduler\" : sch,\n",
    "                \"monitor\" : \"train_loss\",\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.data, batch_size=self.batchsize, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.valid, batch_size=self.batchsize, shuffle=True)\n",
    "    \n",
    "    def acc(self, y_pred, y_true):\n",
    "        c=0\n",
    "        for pred, true in zip(y_pred, y_true):\n",
    "            if th.argmax(pred) == th.argmax(true):\n",
    "                c = c+1\n",
    "        return c/self.batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n",
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n",
      "Your vector field callable (nn.Module) should have both time `t` and state `x` as arguments, we've wrapped it for you.\n"
     ]
    }
   ],
   "source": [
    "PATH = r'./CircuitSolver/'\n",
    "model = CNNODE()\n",
    "t_span = th.linspace(0, 1, 10)\n",
    "data = CircuitFused(PATH, (64, 64))\n",
    "\n",
    "learn = learn.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━┳━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━╇━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model │ CNNODE │  5.6 M │\n",
       "└───┴───────┴────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━┳━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━╇━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model │ CNNODE │  5.6 M │\n",
       "└───┴───────┴────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 5.6 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 5.6 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 22                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 5.6 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 5.6 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 22                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": [
       "\u001b[?25l"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160b8647e2f640368a8912b1d30c1ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[?25h"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "from pytorch_lightning.callbacks.progress.rich_progress import RichProgressBarTheme\n",
    "\n",
    "progress_bar = RichProgressBar(\n",
    "    theme=RichProgressBarTheme(\n",
    "        description=\"blue\",\n",
    "        progress_bar=\"green_yellow\",\n",
    "        progress_bar_finished=\"green1\",\n",
    "        progress_bar_pulse=\"#6206E0\",\n",
    "        batch_progress=\"blue\",\n",
    "        time=\"black\",\n",
    "        processing_speed=\"black\",\n",
    "        metrics=\"black\", \n",
    "    ),\n",
    ")\n",
    "learn = Learner(data, model, t_span, 25, 1e-5)\n",
    "trainer = pl.Trainer(min_epochs=200, max_epochs=300, callbacks=progress_bar, accelerator=\"mps\")\n",
    "trainer.fit(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.save(model, \",.NN97_4.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.cuda.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a580aac5ad65c26b09914c4d39579c9a7b96bf6be88d0e5d5e57a0b213e38927"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
